{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfabadb8-5935-45ff-b39c-db7a29012129",
   "metadata": {
    "id": "bfabadb8-5935-45ff-b39c-db7a29012129"
   },
   "source": [
    "# Chapter 6: Finetuning for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "9495f150-9d79-4910-d6e7-6c0d9aae4a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.4\n",
      "numpy version: 2.0.2\n",
      "tiktoken version: 0.12.0\n",
      "torch version: 2.8.0\n",
      "tensorflow version: 2.20.0\n",
      "pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",  # Plotting library\n",
    "        \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "        \"tiktoken\",    # Tokenizer\n",
    "        \"torch\",       # Deep learning library\n",
    "        \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "        \"pandas\"       # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/01.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c",
   "metadata": {
    "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c"
   },
   "source": [
    "## 6.1 Different categories of finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3d731-5123-4f02-accd-c670ce50a5a3",
   "metadata": {
    "id": "ede3d731-5123-4f02-accd-c670ce50a5a3"
   },
   "source": [
    "- No code in this section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45579d-d485-47dc-829e-43be7f4db57b",
   "metadata": {},
   "source": [
    "- The most common ways to finetune language models are instruction-finetuning and classification finetuning\n",
    "- Instruction-finetuning, depicted below, is the topic of the next chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/02.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd",
   "metadata": {},
   "source": [
    "- Classification finetuning, the topic of this chapter, is a procedure you may already be familiar with if you have a background in machine learning -- it's similar to training a convolutional network to classify handwritten digits, for example\n",
    "- In classification finetuning, we have a specific number of class labels (for example, \"spam\" and \"not spam\") that the model can output\n",
    "- A classification finetuned model can only predict classes it has seen during training (for example, \"spam\" or \"not spam\"), whereas an instruction-finetuned model can usually perform many tasks\n",
    "- We can think of a classification-finetuned model as a very specialized model; in practice, it is much easier to create a specialized model than a generalist model that performs well on many different tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/03.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## 6.2 Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/04.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d",
   "metadata": {
    "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d"
   },
   "source": [
    "- This section prepares the dataset we use for classification finetuning\n",
    "- We use a dataset consisting of spam and non-spam text messages to finetune the LLM to classify them\n",
    "- First, we download and unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "424e4423-f623-443c-ab9e-656f9e867559"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neoli/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimport urllib.request\\nimport zipfile\\nimport os\\nfrom pathlib import Path\\n\\nurl = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\\nzip_path = \"sms_spam_collection.zip\"\\nextracted_path = \"sms_spam_collection\"\\ndata_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\\n\\ndef download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\\n    if data_file_path.exists():\\n        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\\n        return\\n\\n    # Downloading the file\\n    with urllib.request.urlopen(url) as response:\\n        with open(zip_path, \"wb\") as out_file:\\n            out_file.write(response.read())\\n\\n    # Unzipping the file\\n    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\\n        zip_ref.extractall(extracted_path)\\n\\n    # Add .tsv file extension\\n    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\\n    os.rename(original_file_path, data_file_path)\\n    print(f\"File downloaded and saved as {data_file_path}\")\\n\\ntry:\\n    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\\nexcept (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\\n    print(f\"Primary URL failed: {e}. Trying backup URL...\")\\n    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\\n    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    response = requests.get(url, stream=True, timeout=60)\n",
    "    response.raise_for_status()\n",
    "    with open(zip_path, \"wb\") as out_file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                out_file.write(chunk)\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (requests.exceptions.RequestException, TimeoutError) as e:\n",
    "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "\n",
    "\n",
    "\n",
    "# The book originally used the following code below\n",
    "# However, urllib uses older protocol settings that\n",
    "# can cause problems for some readers using a VPN.\n",
    "# The `requests` version above is more robust\n",
    "# in that regard.\n",
    "\n",
    "\"\"\"\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
    "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1",
   "metadata": {
    "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1"
   },
   "source": [
    "- The dataset is saved as a tab-separated text file, which we can load into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
    "outputId": "a16c5cde-d341-4887-a93f-baa9bec542ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109",
   "metadata": {
    "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109"
   },
   "source": [
    "- When we check the class distribution, we see that the data contains \"ham\" (i.e., \"not spam\") much more frequently than \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
    "outputId": "761e0482-43ba-4f46-f4b7-6774dae51b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773f054-0bdc-4aad-bbf6-397621bf63db",
   "metadata": {
    "id": "f773f054-0bdc-4aad-bbf6-397621bf63db"
   },
   "source": [
    "- For simplicity, and because we prefer a small dataset for educational purposes anyway (it will make it possible to finetune the LLM faster), we subsample (undersample) the dataset so that it contains 747 instances from each class\n",
    "- (Next to undersampling, there are several other ways to deal with class balances, but they are out of the scope of a book on LLMs; you can find examples and more information in the [`imbalanced-learn` user guide](https://imbalanced-learn.org/stable/user_guide.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7be4a0a2-9704-4a96-b38f-240339818688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7be4a0a2-9704-4a96-b38f-240339818688",
    "outputId": "396dc415-cb71-4a88-e85d-d88201c6d73f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\" {num_spam x spam instances with 2 columns}\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "# Before\n",
    "# ham     4825\n",
    "# spam     747\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "# After\n",
    "# ham     747\n",
    "# spam    747\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6",
   "metadata": {
    "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6"
   },
   "source": [
    "- Next, we change the string class labels \"ham\" and \"spam\" into integer class labels 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
   "metadata": {
    "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "0    747\n",
      "1    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})  \n",
    "# Label\n",
    "# 0    747\n",
    "# 1    747 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6f7f062-ef4e-4020-8275-71990cab4414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f",
   "metadata": {
    "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f"
   },
   "source": [
    "- Let's now define a function that randomly divides the dataset into training, validation, and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "uQl0Psdmx15D",
   "metadata": {
    "id": "uQl0Psdmx15D"
   },
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094",
   "metadata": {},
   "source": [
    "## 6.3 Creating data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c",
   "metadata": {
    "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c"
   },
   "source": [
    "- Note that the text messages have different lengths; if we want to combine multiple training examples in a batch, we have to either\n",
    "  1. truncate all messages to the length of the shortest message in the dataset or batch\n",
    "  2. pad all messages to the length of the longest message in the dataset or batch\n",
    "\n",
    "- We choose option 2 and pad all messages to the longest message in the dataset\n",
    "- For that, we use `<|endoftext|>` as a padding token, as discussed in chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829f33f-1428-4f22-9886-7fee633b3666",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/06.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
    "outputId": "b5b48439-32c8-4b37-cca2-c9dc8fa86563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f582ff-68bf-450e-bd87-5fb61afe431c",
   "metadata": {
    "id": "04f582ff-68bf-450e-bd87-5fb61afe431c"
   },
   "source": [
    "- The `SpamDataset` class below identifies the longest sequence in the training dataset and adds the padding token to the others to match that sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
   "metadata": {
    "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "        # Note: A more pythonic version to implement this method\n",
    "        # is the following, which is also used in the next chapter:\n",
    "        # return max(len(encoded_text) for encoded_text in self.encoded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "uzj85f8ou82h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzj85f8ou82h",
    "outputId": "d08f1cf0-c24d-445f-a3f8-793532c3716f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60",
   "metadata": {},
   "source": [
    "- We also pad the validation and test set to the longest training sequence\n",
    "- Note that validation and test set samples that are longer than the longest training example are being truncated via `encoded_text[:self.max_length]` in the `SpamDataset` code\n",
    "- This behavior is entirely optional, and it would also work well if we set `max_length=None` in both the validation and test set cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
   "metadata": {
    "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
   },
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20170d89-85a0-4844-9887-832f5d23432a",
   "metadata": {},
   "source": [
    "- Next, we use the dataset to instantiate the data loaders, which is similar to creating the data loaders in previous chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bcc349-205f-48f8-9655-95ff21f5e72f",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/07.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
    "outputId": "3266c410-4fdb-4a8c-a142-7f707e2525ab"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {},
   "source": [
    "- As a verification step, we iterate through the data loaders and ensure that the batches contain 8 training examples each, where each training example consists of 120 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {},
   "source": [
    "- Lastly, let's print the total number of batches in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "6934bbf2-9797-4fbe-d26b-1a246e18c2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c",
   "metadata": {
    "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c"
   },
   "source": [
    "## 6.4 Initializing a model with pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208",
   "metadata": {},
   "source": [
    "- In this section, we initialize the pretrained model we worked with in the previous chapter\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/08.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2992d779-f9fb-4812-a117-553eb790a5a9",
   "metadata": {
    "id": "2992d779-f9fb-4812-a117-553eb790a5a9"
   },
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "022a649a-44f5-466c-8a8e-326c063384f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "022a649a-44f5-466c-8a8e-326c063384f5",
    "outputId": "7091e401-8442-4f47-a1d9-ecb42a1ef930"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 52.2kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.03MiB/s]\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 31.2kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:26<00:00, 18.9MiB/s] \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 2.00MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.12MiB/s]\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.31MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "# If the `previous_chapters.py` file is not available locally,\n",
    "# you can import it from the `llms-from-scratch` PyPI package.\n",
    "# For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
    "# E.g.,\n",
    "# from llms_from_scratch.ch04 import GPTModel\n",
    "# from llms_from_scratch.ch05 import download_and_load_gpt2, load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e056c-abe0-415f-b34d-df686204259e",
   "metadata": {},
   "source": [
    "- To ensure that the model was loaded correctly, let's double-check that it generates coherent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch05 import (\n",
    "#    generate_text_simple,\n",
    "#    text_to_token_ids,\n",
    "#    token_ids_to_text\n",
    "# )\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69162550-6a02-4ece-8db1-06c71d61946f",
   "metadata": {},
   "source": [
    "- Before we finetune the model as a classifier, let's see if the model can perhaps already classify spam messages via prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016",
   "metadata": {},
   "source": [
    "- As we can see, the model is not very good at following instructions\n",
    "- This is expected, since it has only been pretrained and not instruction-finetuned (instruction finetuning will be covered in the next chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522",
   "metadata": {
    "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522"
   },
   "source": [
    "## 6.5 Adding a classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/09.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217bac05-78df-4412-bd80-612f8061c01d",
   "metadata": {},
   "source": [
    "- In this section, we are modifying the pretrained LLM to make it ready for classification finetuning\n",
    "- Let's take a look at the model architecture first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d8f7a01-b7c0-48d4-b1e7-8c12cc7ad932",
    "outputId": "b6a5b9b5-a92f-498f-d7cb-b58dd99e4497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d",
   "metadata": {},
   "source": [
    "- Above, we can see the architecture we implemented in chapter 4 neatly laid out\n",
    "- The goal is to replace and finetune the output layer\n",
    "- To achieve this, we first freeze the model, meaning that we make all layers non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fkMWFl-0etea",
   "metadata": {
    "id": "fkMWFl-0etea"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72155f83-87d9-476a-a978-a15aa2d44147",
   "metadata": {},
   "source": [
    "- Then, we replace the output layer (`model.out_head`), which originally maps the layer inputs to 50,257 dimensions (the size of the vocabulary)\n",
    "- Since we finetune the model for binary classification (predicting 2 classes, \"spam\" and \"not spam\"), we can replace the output layer as shown below, which will be trainable by default\n",
    "- Note that we use `BASE_CONFIG[\"emb_dim\"]` (which is equal to 768 in the `\"gpt2-small (124M)\"` model) to keep the code below more general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be5475-ae77-4f97-8f3e-dec462b1339f",
   "metadata": {},
   "source": [
    "- Technically, it's sufficient to only train the output layer\n",
    "- However, as I found in [Finetuning Large Language Models](https://magazine.sebastianraschka.com/p/finetuning-large-language-models), experiments show that finetuning additional layers can noticeably improve the performance\n",
    "- So, we are also making the last transformer block and the final `LayerNorm` module connecting the last transformer block to the output layer trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/10.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7",
   "metadata": {
    "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7"
   },
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e",
   "metadata": {},
   "source": [
    "- We can still use this model similar to before in previous chapters\n",
    "- For example, let's feed it some text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
    "outputId": "27e041b1-d731-48a1-cf60-f22d4565304e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b",
   "metadata": {},
   "source": [
    "- What's different compared to previous chapters is that it now has two output dimensions instead of 50,257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
    "outputId": "9cae7448-253d-4776-973e-0af190b06354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75430a01-ef9c-426a-aca0-664689c4f461",
   "metadata": {},
   "source": [
    "- As discussed in previous chapters, for each input token, there's one output vector\n",
    "- Since we fed the model a text sample with 4 input tokens, the output consists of 4 2-dimensional output vectors above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/11.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a",
   "metadata": {},
   "source": [
    "- In chapter 3, we discussed the attention mechanism, which connects each input token to each other input token\n",
    "- In chapter 3, we then also introduced the causal attention mask that is used in GPT-like models; this causal mask lets a current token only attend to the current and previous token positions\n",
    "- Based on this causal attention mechanism, the 4th (last) token contains the most information among all tokens because it's the only token that includes information about all other tokens\n",
    "- Hence, we are particularly interested in this last token, which we will finetune for the spam classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
    "outputId": "e79eb155-fa1f-46ed-ff8c-d828c3a3fabd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/12.webp\" width=200px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c",
   "metadata": {},
   "source": [
    "## 6.6 Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/13.webp\" width=300px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3",
   "metadata": {},
   "source": [
    "- Before explaining the loss calculation, let's have a brief look at how the model outputs are turned into class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/14.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c77faab1-3461-4118-866a-6171f2b89aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d",
   "metadata": {},
   "source": [
    "- Similar to chapter 5, we convert the outputs (logits) into probability scores via the `softmax` function and then obtain the index position of the largest probability value via the `argmax` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a6f02-307e-4147-a416-14d115bf8179",
   "metadata": {},
   "source": [
    "- Note that the softmax function is optional here, as explained in chapter 5, because the largest outputs correspond to the largest probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505",
   "metadata": {},
   "source": [
    "- We can apply this concept to calculate the so-called classification accuracy, which computes the percentage of correct predictions in a given dataset\n",
    "- To calculate the classification accuracy, we can apply the preceding `argmax`-based prediction code to all examples in a dataset and calculate the fraction of correct predictions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            # model is in device memory,  so as input need to be in the same place for calculation. \n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token \n",
    "                                                       # batch size x num_classes [8x2]\n",
    "            predicted_labels = torch.argmax(logits, dim=-1) # not keep dim, batch size of lables\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            # == return e.g. tensor([ True,  True, False, False]),  \n",
    "            # sum the value of trues, which is 1. e.g. tensor(2)\n",
    "            # .item unwrap the tensor return the counts.  e.g. 2\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165fe46-a284-410b-957f-7524877d1a1a",
   "metadata": {},
   "source": [
    "- Let's apply the function to calculate the classification accuracies for the different datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "329a155b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4689,  0.7525, -0.6422, -0.8128],\n",
      "        [ 0.2403, -0.5516, -0.5697,  1.0076],\n",
      "        [ 0.4324, -1.4235,  0.5874, -1.2896],\n",
      "        [-0.3155, -0.3656, -0.6605, -0.1104]])\n",
      "tensor([1, 3, 2, 3])\n",
      "tensor([[1],\n",
      "        [3],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([ True,  True, False, False])\n",
      "tensor(2)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.randn(4,4)\n",
    "print(t1)\n",
    "t1_argmax = torch.argmax(t1, dim=-1)\n",
    "print(t1_argmax)\n",
    "t1_argmax_keep_dim = torch.argmax(t1, dim=-1, keepdim=True)\n",
    "print(t1_argmax_keep_dim)\n",
    "\n",
    "\n",
    "# experiments tesnsor opereations. \n",
    "predicted_labels = torch.tensor([0, 1, 0, 1])\n",
    "target_batch = torch.tensor([0, 1, 1, 0])\n",
    "\n",
    "print(predicted_labels == target_batch)\n",
    "print((predicted_labels == target_batch).sum())\n",
    "print((predicted_labels == target_batch).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([0, 0, 1, 0, 0, 0, 1, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([1, 0, 1, 0, 0, 1, 0, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([1, 1, 0, 0, 1, 0, 1, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([0, 0, 1, 0, 1, 1, 0, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([0, 0, 1, 1, 0, 0, 1, 1])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([1, 1, 0, 0, 0, 1, 0, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([1, 1, 0, 0, 1, 0, 1, 1])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([0, 1, 1, 0, 0, 1, 1, 1])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([0, 1, 0, 1, 0, 0, 1, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([1, 1, 1, 1, 0, 0, 1, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([1, 1, 0, 0, 1, 0, 1, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([1, 0, 0, 1, 0, 1, 0, 1])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([0, 1, 0, 0, 1, 0, 1, 1])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([0, 1, 1, 1, 1, 0, 1, 1])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([0, 0, 0, 1, 0, 0, 1, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([0, 0, 0, 1, 1, 0, 1, 1])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([0, 0, 1, 0, 0, 1, 0, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([1, 0, 1, 0, 0, 1, 0, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([0, 1, 1, 0, 1, 0, 0, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([1, 1, 1, 0, 0, 0, 1, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([1, 1, 1, 0, 1, 0, 0, 1])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([1, 0, 1, 1, 0, 0, 1, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([0, 0, 0, 1, 1, 1, 1, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([0, 1, 1, 1, 0, 0, 0, 1])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([1, 1, 0, 1, 1, 1, 0, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([0, 1, 1, 1, 0, 0, 0, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([1, 1, 0, 1, 0, 0, 1, 1])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([1, 0, 1, 0, 1, 0, 1, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([0, 0, 1, 1, 0, 0, 0, 0])\n",
      "Predicted labels: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target labels: tensor([0, 1, 0, 0, 1, 1, 0, 0])\n",
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Use PyTorch 2.9 or newer for stable mps results\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30345e2a-afed-4d22-9486-f4010f90a871",
   "metadata": {},
   "source": [
    "- As we can see, the prediction accuracies are not very good, since we haven't finetuned the model, yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328",
   "metadata": {},
   "source": [
    "- Before we can start finetuning (/training), we first have to define the loss function we want to optimize during training\n",
    "- The goal is to maximize the spam classification accuracy of the model; however, classification accuracy is not a differentiable function\n",
    "- Hence, instead, we minimize the cross-entropy loss as a proxy for maximizing the classification accuracy (you can learn more about this topic in lecture 8 of my freely available [Introduction to Deep Learning](https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression) class)\n",
    "\n",
    "- The `calc_loss_batch` function is the same here as in chapter 5, except that we are only interested in optimizing the last token `model(input_batch)[:, -1, :]` instead of all tokens `model(input_batch)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
   "metadata": {
    "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013aab9-f854-4866-ad55-5b8350adb50a",
   "metadata": {},
   "source": [
    "The `calc_loss_loader` is exactly the same as in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56826ecd-6e74-40e6-b772-d3541e585067",
   "metadata": {},
   "source": [
    "- Using the `calc_closs_loader`, we compute the initial training, validation, and test set losses before we start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
    "outputId": "49df8648-9e38-4314-854d-9faacd1b2e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.194\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d",
   "metadata": {},
   "source": [
    "- In the next section, we train the model to improve the loss values and consequently the classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ae0fd-6261-42b4-ab6a-d24289953083",
   "metadata": {
    "id": "456ae0fd-6261-42b4-ab6a-d24289953083"
   },
   "source": [
    "## 6.7 Finetuning the model on supervised data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b099b-0829-4f72-8a2b-4363e3497026",
   "metadata": {},
   "source": [
    "- In this section, we define and use the training function to improve the classification accuracy of the model\n",
    "- The `train_classifier_simple` function below is practically the same as the `train_model_simple` function we used for pretraining the model in chapter 5\n",
    "- The only two differences are that we now \n",
    "  1. track the number of training examples seen (`examples_seen`) instead of the number of tokens seen\n",
    "  2. calculate the accuracy after each epoch instead of printing a sample text after each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/15.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "Csbr60to50FL",
   "metadata": {
    "id": "Csbr60to50FL"
   },
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}...\")\n",
    "\n",
    "        model.train()  # Set model to training mode\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            \n",
    "            # grad after each batch. \n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                # calc_loss_Loader for training and validation datasets. \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624cb30-3e3a-45be-b006-c00475b58ae8",
   "metadata": {},
   "source": [
    "- The `evaluate_model` function used in the `train_classifier_simple` is the same as the one we used in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9",
   "metadata": {},
   "source": [
    "- The training takes about 5 minutes on a M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "X7kU3aAj7vTJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7kU3aAj7vTJ",
    "outputId": "504a033e-2bf8-41b5-a037-468309845513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5...\n",
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Epoch 2/5...\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Epoch 3/5...\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Epoch 4/5...\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Epoch 5/5...\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 3.43 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261bf90-3ce7-4591-895a-044a05538f30",
   "metadata": {},
   "source": [
    "- Similar to chapter 5, we use matplotlib to plot the loss function for the training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cURgnDqdCeka",
   "metadata": {
    "id": "cURgnDqdCeka"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "OIqRt466DiGk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "OIqRt466DiGk",
    "outputId": "b16987cf-0001-4652-ddaf-02f7cffc34db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc",
   "metadata": {},
   "source": [
    "- Above, based on the downward slope, we see that the model learns well\n",
    "- Furthermore, the fact that the training and validation loss are very close indicates that the model does not tend to overfit the training data\n",
    "- Similarly, we can plot the accuracy below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "yz8BIsaF0TUo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "yz8BIsaF0TUo",
    "outputId": "3a7ed967-1f2a-4c6d-f4a3-0cc8cc9d6c5f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aba699-21bc-42de-a69c-99f370bb0363",
   "metadata": {},
   "source": [
    "- Based on the accuracy plot above, we can see that the model achieves a relatively high training and validation accuracy after epochs 4 and 5\n",
    "- However, we have to keep in mind that we specified `eval_iter=5` in the training function earlier, which means that we only estimated the training and validation set performances\n",
    "- We can compute the training, validation, and test set performances over the complete dataset as follows below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "UHWaJFrjY0zW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHWaJFrjY0zW",
    "outputId": "e111e6e6-b147-4159-eb9d-19d4e809ed34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882649f-dc7b-401f-84d2-024ff79c74a1",
   "metadata": {},
   "source": [
    "- We can see that the training and validation set performances are practically identical\n",
    "- However, based on the slightly lower test set performance, we can see that the model overfits the training data to a very small degree, as well as the validation data that has been used for tweaking some of the hyperparameters, such as the learning rate\n",
    "- This is normal, however, and this gap could potentially be further reduced by increasing the model's dropout rate (`drop_rate`) or the `weight_decay` in the optimizer setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0",
   "metadata": {},
   "source": [
    "## 6.8 Using the LLM as a spam classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebcfa2-479e-408b-9cf0-7421f6144855",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/18.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31",
   "metadata": {},
   "source": [
    "- Finally, let's use the finetuned GPT model in action\n",
    "- The `classify_review` function below implements the data preprocessing steps similar to the `SpamDataset` we implemented earlier\n",
    "- Then, the function returns the predicted integer class label from the model and returns the corresponding class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aHdn6xvL-IW5",
   "metadata": {
    "id": "aHdn6xvL-IW5"
   },
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "    assert max_length is not None, (\n",
    "        \"max_length must be specified. If you want to use the full model context, \"\n",
    "        \"pass max_length=model.pos_emb.weight.shape[0].\"\n",
    "    )\n",
    "    assert max_length <= supported_context_length, (\n",
    "        f\"max_length ({max_length}) exceeds model's supported context length ({supported_context_length}).\"\n",
    "    )    \n",
    "    # Alternatively, a more robust version is the following one, which handles the max_length=None case better\n",
    "    # max_len = min(max_length,supported_context_length) if max_length else supported_context_length\n",
    "    # input_ids = input_ids[:max_len]\n",
    "    \n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c",
   "metadata": {},
   "source": [
    "- Let's try it out on a few examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "apU_pf51AWSV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apU_pf51AWSV",
    "outputId": "d0fde0a5-e7a3-4dbe-d9c5-0567dbab7e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1g5VTOo_Ajs5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1g5VTOo_Ajs5",
    "outputId": "659b08eb-b6a9-4a8a-9af7-d94c757e93c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n",
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))\n",
    "\n",
    "\n",
    "text_3 = (\n",
    "    \"I am US Citizen, if you marry me, You will get greencard it cost you only $5000\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_3, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e",
   "metadata": {},
   "source": [
    "- Finally, let's save the model in case we want to reuse the model later without having to train it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "mYnX-gI1CfQY",
   "metadata": {
    "id": "mYnX-gI1CfQY"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6",
   "metadata": {},
   "source": [
    "- Then, in a new session, we could load the model as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4",
   "metadata": {
    "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4"
   },
   "source": [
    "## Summary and takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e",
   "metadata": {},
   "source": [
    "- See the [./gpt_class_finetune.py](./gpt_class_finetune.py) script, a self-contained script for classification finetuning\n",
    "- You can find the exercise solutions in [./exercise-solutions.ipynb](./exercise-solutions.ipynb)\n",
    "- In addition, interested readers can find an introduction to parameter-efficient training with low-rank adaptation (LoRA) in [appendix E](../../appendix-E)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
